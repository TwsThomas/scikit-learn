{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model, svm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_array\n",
    "\n",
    "from sklearn.utils._testing import assert_array_almost_equal\n",
    "from sklearn.utils._testing import assert_array_equal\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.utils._testing import TempMemmap\n",
    "\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.decomposition import SparseCoder\n",
    "from sklearn.decomposition import dict_learning\n",
    "from sklearn.decomposition import dict_learning_online\n",
    "from sklearn.decomposition import sparse_encode\n",
    "\n",
    "rng_global = np.random.RandomState(0)\n",
    "n_samples, n_features = 10, 8\n",
    "X = rng_global.randn(n_samples, n_features)\n",
    "n_components = 12\n",
    "\n",
    "def test_dict_learning_reconstruction():\n",
    "    n_components = 12\n",
    "    dico = DictionaryLearning(n_components, transform_algorithm='lasso_lars',\n",
    "                              transform_alpha=0.001, random_state=0)\n",
    "    code = dico.fit(X).transform(X)\n",
    "    assert_array_almost_equal(np.dot(code, dico.components_), X, decimal=2)\n",
    "test_dict_learning_reconstruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 12)\n",
      "(12, 8)\n"
     ]
    }
   ],
   "source": [
    "code, dict_, err = dict_learning(X, n_components = 12, alpha = .0001)\n",
    "assert_array_almost_equal(np.dot(code, dict_), X, decimal=2)\n",
    "code, dict_ = dict_learning_online(X, n_components = 12, alpha = .0001)\n",
    "assert_array_almost_equal(np.dot(code, dict_), X, decimal=2)\n",
    "print(code.shape)\n",
    "print(dict_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import sparse_encode\n",
    "code_ = sparse_encode(X, dict_, alpha = .00001)\n",
    "print(code_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "new_X = np.dot(code_, dict_)\n",
    "print(new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_array_almost_equal(np.dot(code_, dict_), X, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition._dict_learning_na import sparse_encode_na\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dict_learning_na(X, n_components=2, alpha=1, n_iter=100):\n",
    "    \n",
    "    code, S, dictionary = linalg.svd(X, full_matrices=False)\n",
    "    dictionary = S[:, np.newaxis] * dictionary\n",
    "    \n",
    "    r = len(dictionary)\n",
    "    if n_components <= r:  # True even if n_components=None\n",
    "        code = code[:, :n_components]\n",
    "        dictionary = dictionary[:n_components, :]\n",
    "    else:\n",
    "        code = np.c_[code, np.zeros((len(code), n_components - r))]\n",
    "        dictionary = np.r_[dictionary,\n",
    "                           np.zeros((n_components - r, dictionary.shape[1]))]\n",
    "\n",
    "        \n",
    "    print(dictionary.shape)\n",
    "    print(code.shape)\n",
    "    \n",
    "    D = dictionary\n",
    "    for x in X:   \n",
    "        \n",
    "        this_code = sparse_encode_na(x, D, alpha)\n",
    "        C, B, e = update1(x, this_code, C, B, e, alpha)\n",
    "        D = update_dict(C, B, e, D, code)\n",
    "        e = update2(e, x, D, this_code)\n",
    "        \n",
    "    return code, D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8)\n",
      "(10, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'update1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2fac665b20c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_learning_na\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-1ea8ae91db9f>\u001b[0m in \u001b[0;36mdict_learning_na\u001b[0;34m(X, n_components, alpha, n_iter)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mthis_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_encode_na\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update1' is not defined"
     ]
    }
   ],
   "source": [
    "dict_learning_na(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â test\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition._dict_learning_na import sparse_encode_na\n",
    "\n",
    "from sklearn.utils._testing import assert_array_almost_equal\n",
    "from sklearn.utils._testing import assert_array_equal\n",
    "\n",
    "\n",
    "def test_shape_encode():\n",
    "    \n",
    "    this_x = X[:5]\n",
    "    this_code = sparse_encode_na(this_x, dict_, alpha=1)\n",
    "    assert this_code.shape == (this_x.shape[0], n_components)\n",
    "    \n",
    "    this_x = X_na[:5]\n",
    "    this_code = sparse_encode_na(this_x, dict_, alpha=1)\n",
    "    assert this_code.shape == (this_x.shape[0], n_components)\n",
    "        \n",
    "def test_encode_reconstruction():\n",
    "    \n",
    "    code = sparse_encode_na(X, dict_, alpha=.0001)\n",
    "    assert_array_almost_equal(np.dot(code, dict_), X, decimal=2)\n",
    "    \n",
    "    code = sparse_encode_na(X_na, dict_, alpha=.0001)\n",
    "    X_new = np.dot(code, dict_)\n",
    "    assert_array_almost_equal(X_new[Mask],\n",
    "                              X[Mask], decimal=2)\n",
    "       \n",
    "def test_dict_learning_na():\n",
    "    \n",
    "    code, dict_ = dict_learning_na(X, n_components = 12, alpha = .0001)\n",
    "    assert_array_almost_equal(np.dot(code, dict_), X, decimal=2)\n",
    "    print(code.shape)\n",
    "    print(dict_.shape)\n",
    "    \n",
    "    \n",
    "rng_global = np.random.RandomState(0)\n",
    "n_samples, n_features = 10, 8\n",
    "n_components = 12\n",
    "X = rng_global.randn(n_samples, n_features)\n",
    "code, dict_ = dict_learning_online(X, n_components = 12, alpha = .0001)\n",
    "\n",
    "X_na = X.copy()\n",
    "X_na[0,0] = np.nan\n",
    "X_na[1,1] = np.nan\n",
    "Mask = np.where(~np.isnan(X_na))\n",
    "\n",
    "test_shape_encode()\n",
    "test_encode_reconstruction()\n",
    "# test_dict_learning_na()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
